{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU5UobcUGdCi"
      },
      "source": [
        "# Financial Document Analysis with Retrieval-Augmented Generation (RAG)\n",
        "\n",
        "This Jupyter Notebook demonstrates a complete workflow for building a Q&A system from financial reports using a Retrieval-Augmented Generation (RAG) architecture. We will process Kyndryl's annual reports, build a sophisticated retrieval system, and re-rank the results for higher accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S5eiZUuGdCi"
      },
      "source": [
        "### Part 1: Data Collection & Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1ScQpCIGdCi"
      },
      "source": [
        "**1.1: Obtain and Ingest Financial Statements**\n",
        "\n",
        "First, we'll install the necessary libraries for our project. Then, we will download the annual reports for the last two fiscal years from the provided URLs and store them locally. This step ensures we have the raw data ready for processing."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \\\n",
        "  accelerate>=1.10.0 \\\n",
        "  datasets>=4.0.0 \\\n",
        "  docling>=2.47.0 \\\n",
        "  faiss-cpu>=1.12.0 \\\n",
        "  huggingface-hub>=0.34.4 \\\n",
        "  ipykernel>=6.30.1 \\\n",
        "  pandas>=2.3.2 \\\n",
        "  pdfplumber>=0.11.7 \\\n",
        "  pymupdf>=1.26.3 \\\n",
        "  pypdf2>=3.0.1 \\\n",
        "  rank-bm25>=0.2.2 \\\n",
        "  sentence-transformers>=5.1.0 \\\n",
        "  sentencepiece>=0.2.1 \\\n",
        "  tableformatter>=0.1.6 \\\n",
        "  tabula>=1.0.5 \\\n",
        "  torch>=2.8.0 \\\n",
        "  transformers>=4.55.4\n"
      ],
      "metadata": {
        "id": "NCgjXbnpGfjG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "j9DJvE_bGdCi"
      },
      "outputs": [],
      "source": [
        "# !pip install PyMuPDF sentence-transformers faiss-cpu rank_bm25 transformers pandas -q\n",
        "import logging\n",
        "import time\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from docling.document_converter import DocumentConverter\n",
        "_log = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVgS1aG-GdCj"
      },
      "source": [
        "# Download financial reports for KYNDRYL HOLDINGS, INC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B98bd6IqGdCj",
        "outputId": "56405c94-5353-4fe6-c0f2-6da287f455d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading annual_reports/0205a5a1-2f59-4ab7-b892-58615604423a.pdf...\n",
            "Downloading annual_reports/1488970a-672b-4caa-ad23-00c77e2b2434.pdf...\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "# Create a directory to store the PDFs\n",
        "if not os.path.exists(\"annual_reports\"):\n",
        "    os.makedirs(\"annual_reports\")\n",
        "\n",
        "pdf_urls = [\n",
        "    \"https://investors.kyndryl.com/static-files/0205a5a1-2f59-4ab7-b892-58615604423a\",  # 2024 Annual Report\n",
        "    \"https://investors.kyndryl.com/static-files/1488970a-672b-4caa-ad23-00c77e2b2434\",  # 2023 Annual Report\n",
        "]\n",
        "pdf_paths = []\n",
        "for url in pdf_urls:\n",
        "    file_name = os.path.join(\"annual_reports\", url.split(\"/\")[-1]) + \".pdf\"\n",
        "    if not os.path.exists(file_name):\n",
        "        print(f\"Downloading {file_name}...\")\n",
        "        with requests.get(url, stream=True) as r:\n",
        "            r.raise_for_status()\n",
        "            with open(file_name, \"wb\") as f:\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "    else:\n",
        "        print(f\"{file_name} already exists.\")\n",
        "    pdf_paths.append(file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC2ISh4YGdCj"
      },
      "source": [
        "**1.2: Convert Documents to Plain Text and Clean**\n",
        "\n",
        "We will use the `Docling` library to parse the downloaded PDF files and extract raw text. We will then apply a basic cleaning function to remove common artifacts like headers, footers, and extra whitespace, which are irrelevant for our Q&A task.\n",
        "\n",
        "The 2024 financial report contains the data for both the year 2024 and 2023."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nIp15nMGdCj",
        "outputId": "f791ca93-8d0a-436b-9c00-857249172d32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing annual_reports/0205a5a1-2f59-4ab7-b892-58615604423a.pdf from page 57 to 59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n",
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Table 0\n",
            "|    |                                                                      | Notes   | Year Ended.2024   | March 31,.2023   | Three Months Ended March 31,.2022   | Year Ended December 31,.2021   |\n",
            "|---:|:---------------------------------------------------------------------|:--------|:------------------|:-----------------|:------------------------------------|:-------------------------------|\n",
            "|  0 | Revenues * . . . . . . . . . . . . . . . . . . . . . . . . . . . . . | 3       | $ 16,052          | $ 17,026         | $ 4,431                             | $ 18,657                       |\n",
            "|  1 | Cost of services ** . . . . . . . . . . . . . . . . . . . . . . .    | 3       | $ 13,189          | $ 14,498         | $ 3,824                             | $ 16,550                       |\n",
            "|  2 | Selling, general and administrative expenses . .                     |         | 2,773             | 2,914            | 690                                 | 2,776                          |\n",
            "|  3 | Workforce rebalancing charges . . . . . . . . . . . . .              | 19      | 138               | 71               | -                                   | 39                             |\n",
            "|  4 | Transaction-related costs (benefits) . . . . . . . . . .             |         | (46)              | 264              | 58                                  | 627                            |\n",
            "|  5 | Impairment expense . . . . . . . . . . . . . . . . . . . . . .       | 10      | -                 | -                | -                                   | 469                            |\n",
            "|  6 | Interest expense . . . . . . . . . . . . . . . . . . . . . . . . . . | 11      | 122               | 94               | 21                                  | 64                             |\n",
            "|  7 | Other expense . . . . . . . . . . . . . . . . . . . . . . . . . . .  |         | 45                | 35               | 27                                  | 35                             |\n",
            "|  8 | Total costs and expenses . . . . . . . . . . . . . . . . . .         |         | $ 16,221          | $ 17,876         | $ 4,620                             | $ 20,560                       |\n",
            "|  9 | Income (loss) before income taxes . . . . . . . . .                  |         | $ (168)           | $ (851)          | $ (189)                             | $ (1,903)                      |\n",
            "| 10 | Provision for income taxes . . . . . . . . . . . . . . .             | 5       | $ 172             | $ 524            | $ 40                                | $ 402                          |\n",
            "| 11 | Net income (loss) . . . . . . . . . . . . . . . . . . . . . . . .    |         | $ (340)           | $ (1,374)        | $ (229)                             | $ (2,304)                      |\n",
            "| 12 | Basic earnings (loss) per share . . . . . . . . . . . . . .          | 6       | $ (1.48)          | $ (6.06)         | $ (1.02)                            | $ (10.28)                      |\n",
            "| 13 | Diluted earnings (loss) per share . . . . . . . . . . . .            |         | (1.48)            | (6.06)           | (1.02)                              | (10.28)                        |\n",
            "| 14 | Weighted-average basic shares outstanding . . .                      | 6       | 229.2             | 226.7            | 224.4                               | 224.1                          |\n",
            "| 15 | Weighted-average diluted shares outstanding. .                       |         | 229.2             | 226.7            | 224.4                               | 224.1                          |\n",
            "## Table 1\n",
            "|    |                                                                                                                                        | Year Ended.2024   | March 31,.2023   | Three Months Ended March 31,.2022   | Year Ended December 31,.2021   |\n",
            "|---:|:---------------------------------------------------------------------------------------------------------------------------------------|:------------------|:-----------------|:------------------------------------|:-------------------------------|\n",
            "|  0 | Net income (loss) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                          | $ (340)           | $ (1,374)        | $ (229)                             | $ (2,304)                      |\n",
            "|  1 | Other comprehensive income (loss), before tax:                                                                                         |                   |                  |                                     |                                |\n",
            "|  2 | Foreign currency translation adjustments:                                                                                              |                   |                  |                                     |                                |\n",
            "|  3 | Foreign currency translation adjustments . . . . . . . . . . . . . . . .                                                               | (36)              | (186)            | (51)                                | 194                            |\n",
            "|  4 | Unrealized losses on net investment hedges. . . . . . . . . . . . . . .                                                                | (11)              | -                | -                                   | -                              |\n",
            "|  5 | Total foreign currency translation adjustments. . . . . . . . . . . . . .                                                              | (47)              | (186)            | (51)                                | 194                            |\n",
            "|  6 | Unrealized gains (losses) on cash flow hedges:                                                                                         |                   |                  |                                     |                                |\n",
            "|  7 | Unrealized gains (losses) arising during the period . . . . . . . . .                                                                  | 22                | (4)              | 1                                   | 4                              |\n",
            "|  8 | Reclassification of (gains) losses to net income. . . . . . . . . . . .                                                                | (21)              | 2                | (1)                                 | (1)                            |\n",
            "|  9 | Total unrealized gains (losses) on cash flow hedges . . . . . . . . .                                                                  | 1                 | (3)              | -                                   | 3                              |\n",
            "| 10 | Retirement-related benefit plans:                                                                                                      |                   |                  |                                     |                                |\n",
            "| 11 | Prior service costs (credits) . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                  | (3)               | 4                | -                                   | 1                              |\n",
            "| 12 | Net gains (losses) arising during the period . . . . . . . . . . . . . . .                                                             | (56)              | 175              | 136                                 | 72                             |\n",
            "| 13 | Curtailments and settlements. . . . . . . . . . . . . . . . . . . . . . . . . . .                                                      | 10                | 10               | 4                                   | 3                              |\n",
            "| 14 | Amortization of prior service (credits) costs . . . . . . . . . . . . . .                                                              | 1                 | 1                | -                                   | -                              |\n",
            "| 15 | Amortization of net (gains) losses. . . . . . . . . . . . . . . . . . . . . . .                                                        | 5                 | 40               | 16                                  | 51                             |\n",
            "| 16 | Total retirement-related benefit plans . . . . . . . . . . . . . . . . . . . . .                                                       | (42)              | 229              | 156                                 | 127                            |\n",
            "| 17 | Other comprehensive income (loss), before tax . . . . . . . . . . . .                                                                  | (88)              | 40               | 105                                 | 324                            |\n",
            "| 18 | Income tax (expense) benefit related to items of other comprehensive income (loss) . . . . . . . . . . . . . . . . . . . . . . . . . . | 6                 | (14)             | (50)                                | (33)                           |\n",
            "| 19 | Other comprehensive income (loss), net of tax . . . . . . . . . . . . .                                                                | (82)              | 27               | 54                                  | 292                            |\n",
            "| 20 | Total comprehensive income (loss) . . . . . . . . . . . . . . . . . . . . . . .                                                        | $ (423)           | $ (1,347)        | $ (175)                             | $ (2,013)                      |\n",
            "## Table 2\n",
            "|    |                                                                                                                                                                                                                               | Notes   | 2024     | 2023     |\n",
            "|---:|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------|:---------|:---------|\n",
            "|  0 | Assets:                                                                                                                                                                                                                       |         |          |          |\n",
            "|  1 | Current assets:                                                                                                                                                                                                               |         |          |          |\n",
            "|  2 | Cash and cash equivalents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                               |         | $ 1,553  | $ 1,847  |\n",
            "|  3 | Restricted cash . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                         |         | 1        | 12       |\n",
            "|  4 | Accounts receivable (net of allowances for credit losses of $22 at March 31, 2024 and $32 at March 31, 2023). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . |         | 1,599    | 1,523    |\n",
            "|  5 | Deferred costs (current portion) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                | 3       | 1,081    | 1,070    |\n",
            "|  6 | Prepaid expenses and other current assets. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                      |         | 514      | 510      |\n",
            "|  7 | Total current assets. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                       |         | $ 4,747  | $ 4,963  |\n",
            "|  8 | Property and equipment, net . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                             |         |          |          |\n",
            "|  9 |                                                                                                                                                                                                                               | 8       | $ 2,674  | $ 2,779  |\n",
            "| 10 | Operating right-of-use assets, net . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                              | 9       | 864      | 964      |\n",
            "| 11 | Deferred costs (noncurrent portion). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                | 3       | 920      | 1,166    |\n",
            "| 12 | Deferred taxes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                    | 5       | 220      | 248      |\n",
            "| 13 | Goodwill . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                      | 10      | 805      | 812      |\n",
            "| 14 | Intangible assets, net. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                               | 10      | 188      | 171      |\n",
            "| 15 | Pension assets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                              | 16      | 105      | 94       |\n",
            "| 16 | Other noncurrent assets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                           |         | 67       | 267      |\n",
            "| 17 | Total assets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                  |         | $ 10,590 | $ 11,464 |\n",
            "| 18 | Liabilities:                                                                                                                                                                                                                  |         |          |          |\n",
            "| 19 | Current liabilities:                                                                                                                                                                                                          |         |          |          |\n",
            "| 20 | Accounts payable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                                                |         | $ 1,408  | $ 1,774  |\n",
            "| 21 | . . . . . . . . . . . . . . . . . . Value-added tax and income tax liabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                  |         | 327      | 347      |\n",
            "| 22 | Current portion of long-term debt. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                  | 11      | 126      | 110      |\n",
            "| 23 | Accrued compensation and benefits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                     |         | 609      | 533      |\n",
            "| 24 | Deferred income (current portion) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                   | 3       | 825      | 820      |\n",
            "| 25 | Operating lease liabilities (current portion). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                    | 9       | 285      | 316      |\n",
            "| 26 | Accrued contract costs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                             |         | 487      | 346      |\n",
            "| 27 | Other accrued expenses and liabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                    | 12      | 521      | 624      |\n",
            "| 28 | Total current liabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                       |         | $ 4,589  | $ 4,868  |\n",
            "| 29 | Long-term debt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                        | 11      | $ 3,112  | $ 3,111  |\n",
            "| 30 | Retirement and nonpension postretirement benefit obligations. . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                               | 16      | 500      | 504      |\n",
            "| 31 | . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                                                               | 3       | 314      | 362      |\n",
            "| 32 | Deferred income (noncurrent portion) . . . . Operating lease liabilities (noncurrent portion) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                       | 9       | 622      | 707      |\n",
            "| 33 | Other noncurrent liabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                          | 12      | 332      | 450      |\n",
            "| 34 | Total liabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                 |         | $ 9,468  | $ 10,002 |\n",
            "| 35 | Commitments and contingencies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                               | 13      |          |          |\n",
            "| 36 | Equity:                                                                                                                                                                                                                       |         |          |          |\n",
            "| 37 | Stockholders' equity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                      | 14      |          |          |\n",
            "| 38 | Common stock, par value $0.01 per share, and additional paid-in capital (shares authorized: 1,000.0; shares issued: March 31, 2024 - 233.7, March 31, 2023 - 229.6)                                                           |         | $ 4,524  | $ 4,428  |\n",
            "| 39 | Accumulated deficit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                         |         | (2,319)  | (1,978)  |\n",
            "| 40 | Treasury stock, at cost (shares: March 31, 2024 - 3.3, March 31, 2023 - 1.9). . . . . . . . . . . . . . .                                                                                                                     |         | (45)     | (23)     |\n",
            "| 41 | Accumulated other comprehensive income (loss) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                           |         | (1,145)  | (1,062)  |\n",
            "| 42 | Total stockholders' equity before non-controlling interests . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                                           |         | $ 1,015  | $ 1,365  |\n",
            "| 43 | Non-controlling interests . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                           |         | 107      | 97       |\n",
            "| 44 | Total equity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                  |         | $ 1,122  | $ 1,462  |\n",
            "| 45 | Total liabilities and equity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                                                                        |         | $ 10,590 | $ 11,464 |\n"
          ]
        }
      ],
      "source": [
        "def parse_pdf(pdf_path, start, end):\n",
        "    print(f\"Parsing {pdf_path} from page {start} to {end}\")\n",
        "    res = []\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "    input_doc_path = pdf_path\n",
        "    output_dir = Path(\"scratch\")\n",
        "\n",
        "    doc_converter = DocumentConverter()\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    conv_res = doc_converter.convert(input_doc_path, page_range=(start, end))\n",
        "\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    doc_filename = conv_res.input.file.stem\n",
        "\n",
        "    # Export tables\n",
        "    for table_ix, table in enumerate(conv_res.document.tables):\n",
        "        table_df: pd.DataFrame = table.export_to_dataframe()\n",
        "        print(f\"## Table {table_ix}\")\n",
        "        res.append(table_df)\n",
        "        print(table_df.to_markdown())\n",
        "\n",
        "        # Save the table as csv\n",
        "        element_csv_filename = output_dir / f\"{doc_filename}-table-{table_ix + 1}.csv\"\n",
        "        _log.info(f\"Saving CSV table to {element_csv_filename}\")\n",
        "        table_df.to_csv(element_csv_filename)\n",
        "\n",
        "    end_time = time.time() - start_time\n",
        "\n",
        "    _log.info(f\"Document converted and tables exported in {end_time:.2f} seconds.\")\n",
        "    return res\n",
        "\n",
        "# let's parse pdf from the pages 57 to 59. The pages that contain financial tables.\n",
        "# The 2024 financial report contains the data for both the year 2024 and 2023.\n",
        "raw_documents = parse_pdf(pdf_paths[0], 57, 59)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dR5knpSGdCj"
      },
      "source": [
        "### Clean text and Segment reports into logical sections\n",
        "\n",
        "The above parsed document has financial data for 2024, 2023, 2022 and 2021. Let's clean up and extract for 2024 and 2023.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTgXnWxfGdCj"
      },
      "source": [
        "#### Process INCOME statement\n",
        "1. KYNDRYL HOLDINGS, INC. CONSOLIDATED INCOME STATEMENT\n",
        "2. KYNDRYL HOLDINGS, INC. CONSOLIDATED STATEMENT OF COMPREHENSIVE INCOME (LOSS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-KdRe-DGdCj",
        "outputId": "18855837-422a-4e48-9349-a249e5096b59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Questions and Answers\n",
            "[('Revenues of 2024?', '$ 16,052 million.'), ('Cost of services of 2024?', '$ 13,189 million.')]\n",
            "[('Cost of services of 2023?', '$ 14,498 million.'), ('Selling, general and administrative expenses of 2023?', '2,914 million.')]\n"
          ]
        }
      ],
      "source": [
        "from itertools import chain\n",
        "\n",
        "qa_documents = {}\n",
        "\n",
        "questions_2023 = []\n",
        "questions_2024 = []\n",
        "\n",
        "# iterate over income statement tables and create simple Q&A pairs\n",
        "for row in chain(raw_documents[0].itertuples(), raw_documents[1].itertuples()):\n",
        "    if not row[3] and not row[4]:\n",
        "        continue\n",
        "    question_suffix = \"?\"\n",
        "    question_prefix = f'{row[1].strip(\".* :\").rstrip()} of'\n",
        "    answer_suffix = \".\" if \"per share\" in question_prefix.lower() else \" million.\"\n",
        "\n",
        "    question = question_prefix + \" 2024\" + question_suffix\n",
        "    answer = row[3]\n",
        "    answer = \"Not applicable\" if answer == \"-\" else (answer + answer_suffix)\n",
        "    questions_2024.append((question, answer))\n",
        "\n",
        "    question = question_prefix + \" 2023\" + question_suffix\n",
        "    answer = row[4]\n",
        "    answer = \"Not applicable\" if answer == \"-\" else (answer + answer_suffix)\n",
        "    questions_2023.append((question, answer))\n",
        "\n",
        "print(\"Sample Questions and Answers\")\n",
        "print(questions_2024[:2])\n",
        "print(questions_2023[1:3])\n",
        "\n",
        "qa_documents['Income Statement 2024'] = questions_2024\n",
        "qa_documents['Income Statement 2023'] = questions_2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueEui4aVGdCj"
      },
      "source": [
        "#### Process KYNDRYL HOLDINGS, INC. CONSOLIDATED BALANCE SHEET\n",
        "(In millions, except per share amounts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5J6Q9jHGdCj",
        "outputId": "a98195f6-6756-4586-c17e-335e178dfe0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Questions and Answers\n",
            "[('Other noncurrent liabilities of 2024?', '332 million.'), ('Total liabilities of 2024?', '$ 9,468 million.')]\n",
            "[('Total liabilities of 2023?', '$ 10,002 million.')]\n",
            "Total 2024 Q&A pairs: 26\n",
            "Total 2023 Q&A pairs: 26\n"
          ]
        }
      ],
      "source": [
        "questions_2023 = []\n",
        "questions_2024 = []\n",
        "common_prefix = \"\"\n",
        "skip = False\n",
        "\n",
        "# iterate over the balance sheet table and create simple Q&A pairs\n",
        "for row in raw_documents[2].itertuples():\n",
        "    question_suffix = \"?\"\n",
        "    question_prefix = f'{row[1].rstrip(\".* :\").rstrip()}'\n",
        "    if question_prefix.endswith(\"Assets\") and not row[3]:\n",
        "        common_prefix = \" assets\"\n",
        "    elif question_prefix.endswith(\"Liabilities\") and not row[3]:\n",
        "        common_prefix = \" liabilities\"\n",
        "    elif question_prefix.endswith(\"Equity\") and not row[3]:\n",
        "        break\n",
        "    if not row[3] and not row[4]:\n",
        "        continue\n",
        "\n",
        "    if not question_prefix:\n",
        "        skip = True\n",
        "        continue\n",
        "    elif skip:\n",
        "        skip = False\n",
        "        continue\n",
        "\n",
        "    answer_suffix = \".\" if \"per share\" in question_prefix.lower() else \" million.\"\n",
        "\n",
        "    question = (\n",
        "        (\n",
        "            question_prefix\n",
        "            if question_prefix.endswith(common_prefix)\n",
        "            else f\"{question_prefix}{common_prefix}\"\n",
        "        )\n",
        "        + \" of 2024\"\n",
        "        + question_suffix\n",
        "    )\n",
        "    answer = row[3] + answer_suffix\n",
        "    questions_2024.append((question, answer))\n",
        "    question = (\n",
        "        (\n",
        "            question_prefix\n",
        "            if question_prefix.endswith(common_prefix)\n",
        "            else f\"{question_prefix}{common_prefix}\"\n",
        "        )\n",
        "        + \" of 2023\"\n",
        "        + question_suffix\n",
        "    )\n",
        "    answer = row[4] + answer_suffix\n",
        "    questions_2023.append((question, answer))\n",
        "\n",
        "print(\"Sample Questions and Answers\")\n",
        "print(questions_2024[-2:])\n",
        "print(questions_2023[-1:])\n",
        "\n",
        "print(f\"Total 2024 Q&A pairs: {len(questions_2024)}\")\n",
        "print(f\"Total 2023 Q&A pairs: {len(questions_2023)}\")\n",
        "\n",
        "qa_documents['Balance Sheet 2024'] = questions_2024\n",
        "qa_documents['Balance Sheet 2023'] = questions_2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa414si1GdCk"
      },
      "source": [
        "#### Q/A Pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Xd8kq2uGdCk",
        "outputId": "8d792023-c8a1-4e14-c247-c3095c467b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document: Income Statement 2024\n",
            "Q: Revenues of 2024?\n",
            "A: $ 16,052 million.\n",
            "\n",
            "Q: Cost of services of 2024?\n",
            "A: $ 13,189 million.\n",
            "\n",
            "Q: Selling, general and administrative expenses of 2024?\n",
            "A: 2,773 million.\n",
            "\n",
            "Q: Workforce rebalancing charges of 2024?\n",
            "A: 138 million.\n",
            "\n",
            "Q: Transaction-related costs (benefits) of 2024?\n",
            "A: (46) million.\n",
            "\n",
            "Q: Impairment expense of 2024?\n",
            "A: Not applicable\n",
            "\n",
            "Q: Interest expense of 2024?\n",
            "A: 122 million.\n",
            "\n",
            "Q: Other expense of 2024?\n",
            "A: 45 million.\n",
            "\n",
            "Q: Total costs and expenses of 2024?\n",
            "A: $ 16,221 million.\n",
            "\n",
            "Q: Income (loss) before income taxes of 2024?\n",
            "A: $ (168) million.\n",
            "\n",
            "Q: Provision for income taxes of 2024?\n",
            "A: $ 172 million.\n",
            "\n",
            "Q: Net income (loss) of 2024?\n",
            "A: $ (340) million.\n",
            "\n",
            "Q: Basic earnings (loss) per share of 2024?\n",
            "A: $ (1.48).\n",
            "\n",
            "Q: Diluted earnings (loss) per share of 2024?\n",
            "A: (1.48).\n",
            "\n",
            "Q: Weighted-average basic shares outstanding of 2024?\n",
            "A: 229.2 million.\n",
            "\n",
            "Q: Weighted-average diluted shares outstanding of 2024?\n",
            "A: 229.2 million.\n",
            "\n",
            "Q: Net income (loss) of 2024?\n",
            "A: $ (1,374) million.\n",
            "\n",
            "Q: Foreign currency translation adjustments of 2024?\n",
            "A: (186) million.\n",
            "\n",
            "Q: Unrealized losses on net investment hedges of 2024?\n",
            "A: Not applicable\n",
            "\n",
            "Q: Total foreign currency translation adjustments of 2024?\n",
            "A: (186) million.\n",
            "\n",
            "Q: Unrealized gains (losses) arising during the period of 2024?\n",
            "A: (4) million.\n",
            "\n",
            "Q: Reclassification of (gains) losses to net income of 2024?\n",
            "A: 2 million.\n",
            "\n",
            "Q: Total unrealized gains (losses) on cash flow hedges of 2024?\n",
            "A: (3) million.\n",
            "\n",
            "Q: Prior service costs (credits) of 2024?\n",
            "A: 4 million.\n",
            "\n",
            "Q: Net gains (losses) arising during the period of 2024?\n",
            "A: 175 million.\n",
            "\n",
            "Q: Curtailments and settlements of 2024?\n",
            "A: 10 million.\n",
            "\n",
            "Q: Amortization of prior service (credits) costs of 2024?\n",
            "A: 1 million.\n",
            "\n",
            "Q: Amortization of net (gains) losses of 2024?\n",
            "A: 40 million.\n",
            "\n",
            "Q: Total retirement-related benefit plans of 2024?\n",
            "A: 229 million.\n",
            "\n",
            "Q: Other comprehensive income (loss), before tax of 2024?\n",
            "A: 40 million.\n",
            "\n",
            "Q: Income tax (expense) benefit related to items of other comprehensive income (loss) of 2024?\n",
            "A: (14) million.\n",
            "\n",
            "Q: Other comprehensive income (loss), net of tax of 2024?\n",
            "A: 27 million.\n",
            "\n",
            "Q: Total comprehensive income (loss) of 2024?\n",
            "A: $ (1,347) million.\n",
            "\n",
            "\n",
            "Document: Income Statement 2023\n",
            "Q: Revenues of 2023?\n",
            "A: $ 17,026 million.\n",
            "\n",
            "Q: Cost of services of 2023?\n",
            "A: $ 14,498 million.\n",
            "\n",
            "Q: Selling, general and administrative expenses of 2023?\n",
            "A: 2,914 million.\n",
            "\n",
            "Q: Workforce rebalancing charges of 2023?\n",
            "A: 71 million.\n",
            "\n",
            "Q: Transaction-related costs (benefits) of 2023?\n",
            "A: 264 million.\n",
            "\n",
            "Q: Impairment expense of 2023?\n",
            "A: Not applicable\n",
            "\n",
            "Q: Interest expense of 2023?\n",
            "A: 94 million.\n",
            "\n",
            "Q: Other expense of 2023?\n",
            "A: 35 million.\n",
            "\n",
            "Q: Total costs and expenses of 2023?\n",
            "A: $ 17,876 million.\n",
            "\n",
            "Q: Income (loss) before income taxes of 2023?\n",
            "A: $ (851) million.\n",
            "\n",
            "Q: Provision for income taxes of 2023?\n",
            "A: $ 524 million.\n",
            "\n",
            "Q: Net income (loss) of 2023?\n",
            "A: $ (1,374) million.\n",
            "\n",
            "Q: Basic earnings (loss) per share of 2023?\n",
            "A: $ (6.06).\n",
            "\n",
            "Q: Diluted earnings (loss) per share of 2023?\n",
            "A: (6.06).\n",
            "\n",
            "Q: Weighted-average basic shares outstanding of 2023?\n",
            "A: 226.7 million.\n",
            "\n",
            "Q: Weighted-average diluted shares outstanding of 2023?\n",
            "A: 226.7 million.\n",
            "\n",
            "Q: Net income (loss) of 2023?\n",
            "A: $ (229) million.\n",
            "\n",
            "Q: Foreign currency translation adjustments of 2023?\n",
            "A: (51) million.\n",
            "\n",
            "Q: Unrealized losses on net investment hedges of 2023?\n",
            "A: Not applicable\n",
            "\n",
            "Q: Total foreign currency translation adjustments of 2023?\n",
            "A: (51) million.\n",
            "\n",
            "Q: Unrealized gains (losses) arising during the period of 2023?\n",
            "A: 1 million.\n",
            "\n",
            "Q: Reclassification of (gains) losses to net income of 2023?\n",
            "A: (1) million.\n",
            "\n",
            "Q: Total unrealized gains (losses) on cash flow hedges of 2023?\n",
            "A: Not applicable\n",
            "\n",
            "Q: Prior service costs (credits) of 2023?\n",
            "A: Not applicable\n",
            "\n",
            "Q: Net gains (losses) arising during the period of 2023?\n",
            "A: 136 million.\n",
            "\n",
            "Q: Curtailments and settlements of 2023?\n",
            "A: 4 million.\n",
            "\n",
            "Q: Amortization of prior service (credits) costs of 2023?\n",
            "A: Not applicable\n",
            "\n",
            "Q: Amortization of net (gains) losses of 2023?\n",
            "A: 16 million.\n",
            "\n",
            "Q: Total retirement-related benefit plans of 2023?\n",
            "A: 156 million.\n",
            "\n",
            "Q: Other comprehensive income (loss), before tax of 2023?\n",
            "A: 105 million.\n",
            "\n",
            "Q: Income tax (expense) benefit related to items of other comprehensive income (loss) of 2023?\n",
            "A: (50) million.\n",
            "\n",
            "Q: Other comprehensive income (loss), net of tax of 2023?\n",
            "A: 54 million.\n",
            "\n",
            "Q: Total comprehensive income (loss) of 2023?\n",
            "A: $ (175) million.\n",
            "\n",
            "\n",
            "Document: Balance Sheet 2024\n",
            "Q: Cash and cash equivalents assets of 2024?\n",
            "A: $ 1,553 million.\n",
            "\n",
            "Q: Restricted cash assets of 2024?\n",
            "A: 1 million.\n",
            "\n",
            "Q: Accounts receivable (net of allowances for credit losses of $22 at March 31, 2024 and $32 at March 31, 2023) assets of 2024?\n",
            "A: 1,599 million.\n",
            "\n",
            "Q: Deferred costs (current portion) assets of 2024?\n",
            "A: 1,081 million.\n",
            "\n",
            "Q: Prepaid expenses and other current assets of 2024?\n",
            "A: 514 million.\n",
            "\n",
            "Q: Total current assets of 2024?\n",
            "A: $ 4,747 million.\n",
            "\n",
            "Q: Deferred costs (noncurrent portion) assets of 2024?\n",
            "A: 920 million.\n",
            "\n",
            "Q: Deferred taxes assets of 2024?\n",
            "A: 220 million.\n",
            "\n",
            "Q: Goodwill assets of 2024?\n",
            "A: 805 million.\n",
            "\n",
            "Q: Intangible assets, net assets of 2024?\n",
            "A: 188 million.\n",
            "\n",
            "Q: Pension assets of 2024?\n",
            "A: 105 million.\n",
            "\n",
            "Q: Other noncurrent assets of 2024?\n",
            "A: 67 million.\n",
            "\n",
            "Q: Total assets of 2024?\n",
            "A: $ 10,590 million.\n",
            "\n",
            "Q: Accounts payable liabilities of 2024?\n",
            "A: $ 1,408 million.\n",
            "\n",
            "Q: . . . . . . . . . . . . . . . . . . Value-added tax and income tax liabilities of 2024?\n",
            "A: 327 million.\n",
            "\n",
            "Q: Current portion of long-term debt liabilities of 2024?\n",
            "A: 126 million.\n",
            "\n",
            "Q: Accrued compensation and benefits liabilities of 2024?\n",
            "A: 609 million.\n",
            "\n",
            "Q: Deferred income (current portion) liabilities of 2024?\n",
            "A: 825 million.\n",
            "\n",
            "Q: Operating lease liabilities (current portion) liabilities of 2024?\n",
            "A: 285 million.\n",
            "\n",
            "Q: Accrued contract costs liabilities of 2024?\n",
            "A: 487 million.\n",
            "\n",
            "Q: Other accrued expenses and liabilities of 2024?\n",
            "A: 521 million.\n",
            "\n",
            "Q: Total current liabilities of 2024?\n",
            "A: $ 4,589 million.\n",
            "\n",
            "Q: Long-term debt liabilities of 2024?\n",
            "A: $ 3,112 million.\n",
            "\n",
            "Q: Retirement and nonpension postretirement benefit obligations liabilities of 2024?\n",
            "A: 500 million.\n",
            "\n",
            "Q: Other noncurrent liabilities of 2024?\n",
            "A: 332 million.\n",
            "\n",
            "Q: Total liabilities of 2024?\n",
            "A: $ 9,468 million.\n",
            "\n",
            "\n",
            "Document: Balance Sheet 2023\n",
            "Q: Cash and cash equivalents assets of 2023?\n",
            "A: $ 1,847 million.\n",
            "\n",
            "Q: Restricted cash assets of 2023?\n",
            "A: 12 million.\n",
            "\n",
            "Q: Accounts receivable (net of allowances for credit losses of $22 at March 31, 2024 and $32 at March 31, 2023) assets of 2023?\n",
            "A: 1,523 million.\n",
            "\n",
            "Q: Deferred costs (current portion) assets of 2023?\n",
            "A: 1,070 million.\n",
            "\n",
            "Q: Prepaid expenses and other current assets of 2023?\n",
            "A: 510 million.\n",
            "\n",
            "Q: Total current assets of 2023?\n",
            "A: $ 4,963 million.\n",
            "\n",
            "Q: Deferred costs (noncurrent portion) assets of 2023?\n",
            "A: 1,166 million.\n",
            "\n",
            "Q: Deferred taxes assets of 2023?\n",
            "A: 248 million.\n",
            "\n",
            "Q: Goodwill assets of 2023?\n",
            "A: 812 million.\n",
            "\n",
            "Q: Intangible assets, net assets of 2023?\n",
            "A: 171 million.\n",
            "\n",
            "Q: Pension assets of 2023?\n",
            "A: 94 million.\n",
            "\n",
            "Q: Other noncurrent assets of 2023?\n",
            "A: 267 million.\n",
            "\n",
            "Q: Total assets of 2023?\n",
            "A: $ 11,464 million.\n",
            "\n",
            "Q: Accounts payable liabilities of 2023?\n",
            "A: $ 1,774 million.\n",
            "\n",
            "Q: . . . . . . . . . . . . . . . . . . Value-added tax and income tax liabilities of 2023?\n",
            "A: 347 million.\n",
            "\n",
            "Q: Current portion of long-term debt liabilities of 2023?\n",
            "A: 110 million.\n",
            "\n",
            "Q: Accrued compensation and benefits liabilities of 2023?\n",
            "A: 533 million.\n",
            "\n",
            "Q: Deferred income (current portion) liabilities of 2023?\n",
            "A: 820 million.\n",
            "\n",
            "Q: Operating lease liabilities (current portion) liabilities of 2023?\n",
            "A: 316 million.\n",
            "\n",
            "Q: Accrued contract costs liabilities of 2023?\n",
            "A: 346 million.\n",
            "\n",
            "Q: Other accrued expenses and liabilities of 2023?\n",
            "A: 624 million.\n",
            "\n",
            "Q: Total current liabilities of 2023?\n",
            "A: $ 4,868 million.\n",
            "\n",
            "Q: Long-term debt liabilities of 2023?\n",
            "A: $ 3,111 million.\n",
            "\n",
            "Q: Retirement and nonpension postretirement benefit obligations liabilities of 2023?\n",
            "A: 504 million.\n",
            "\n",
            "Q: Other noncurrent liabilities of 2023?\n",
            "A: 450 million.\n",
            "\n",
            "Q: Total liabilities of 2023?\n",
            "A: $ 10,002 million.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for doc, questions in qa_documents.items():\n",
        "    print(f\"\\nDocument: {doc}\")\n",
        "    for q, a in questions:\n",
        "        print(f\"Q: {q}\\nA: {a}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pcgQyE8GdCk"
      },
      "source": [
        "### Part 2: Retrieval-Augmented Generation (RAG) System Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K433WdQGdCk"
      },
      "source": [
        "**2.1 Data Processing: Chunking**\n",
        "\n",
        "To prepare the text for retrieval, we'll split it into smaller, manageable chunks. This allows the model to find more specific and relevant passages. We will create two sets of chunks with different sizes (100 and 400 tokens) to analyze the impact of chunk size on retrieval performance. Each chunk will be assigned a unique ID and metadata indicating its source document and chunk size.\n",
        "\n",
        "The metadata will have info whether the chunk is courced from balance sheet or income statement segments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoO_WA49GdCk",
        "outputId": "d5d3e16a-1ec9-4b9c-f098-7da1986b81a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of chunks created: 236\n",
            "Sample chunk: {'id': 'Income Statement 2024_0_size_100_chunk_0', 'text': 'q : revenues of 2024? a : $ 16, 052 million.', 'metadata': {'segment': 'Income Statement 2024', 'qa_index': 0, 'chunk_size': 100}}\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def chunk_text(qa_list, chunk_size, source_key):\n",
        "    chunks = []\n",
        "    for idx, (q, a) in enumerate(qa_list):\n",
        "        text_block = f\"Q: {q}\\nA: {a}\"\n",
        "        tokens = tokenizer.encode(text_block)\n",
        "        for i in range(0, len(tokens), chunk_size):\n",
        "            chunk_tokens = tokens[i:i + chunk_size]\n",
        "            chunk_str = tokenizer.decode(chunk_tokens, skip_special_tokens=True)\n",
        "            chunks.append({\n",
        "                \"id\": f\"{source_key}_{idx}_size_{chunk_size}_chunk_{len(chunks)}\",\n",
        "                \"text\": chunk_str,\n",
        "                \"metadata\": {\n",
        "                    \"segment\": source_key,\n",
        "                    \"qa_index\": idx,\n",
        "                    \"chunk_size\": chunk_size\n",
        "                }\n",
        "            })\n",
        "    return chunks\n",
        "\n",
        "chunk_sizes = [100, 400]\n",
        "all_chunks = []\n",
        "\n",
        "for size in chunk_sizes:\n",
        "    for key in qa_documents:\n",
        "        all_chunks.extend(chunk_text(qa_documents[key], size, key))\n",
        "\n",
        "print(f\"Total number of chunks created: {len(all_chunks)}\")\n",
        "print(\"Sample chunk:\", all_chunks[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-fFvNT8GdCk"
      },
      "source": [
        "**2.2 Embedding & Indexing**\n",
        "\n",
        "Next, we will convert the text chunks into numerical vectors (embeddings) using the `all-MiniLM-L6-v2` model. These embeddings capture the semantic meaning of the text.\n",
        "\n",
        "We will build two types of indexes:\n",
        "1.  **Dense Vector Store (FAISS):** For fast semantic similarity search.\n",
        "2.  **Sparse Index (BM25):** For efficient keyword-based retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "8021a278f3f44c978c4abe1aa696ac48",
            "f50d726bd70e4d06aa4ed7392b917bfd",
            "2ccfd73731364a10bc4e5133004f7aed",
            "7bfad41bab214d9fa10a911b73092d3f",
            "7c0c1655c5d44edca6dba07bd754ca99",
            "fbd460116d154571a73b83ed842acc64",
            "7446cfbce4e94f69b0057cba8bff4ad1",
            "6fbe551413c44965839ca1b7c13e29d1",
            "ba9c03096fbd4937b0ffdfaf42983ef2",
            "c472af458952457b97109019c9df0d5a",
            "7a49f44f4ec944c1bca765af6e9d45fa"
          ]
        },
        "id": "NbaKG0kaGdCk",
        "outputId": "e03faed5-7ae9-4afd-b436-8cd9fb37cf83"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8021a278f3f44c978c4abe1aa696ac48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index built with 236 vectors.\n",
            "BM25 index built.\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "# 1. Embed Chunks\n",
        "embedding_model = SentenceTransformer(model_name)\n",
        "chunk_texts = [chunk['text'] for chunk in all_chunks]\n",
        "embeddings = embedding_model.encode(chunk_texts, convert_to_numpy=True, show_progress_bar=True)\n",
        "\n",
        "# 2. Build Dense Vector Store (FAISS)\n",
        "embedding_dim = embeddings.shape[1]\n",
        "faiss_index = faiss.IndexFlatL2(embedding_dim)\n",
        "faiss_index.add(np.array(embeddings, dtype=np.float32))\n",
        "print(f\"FAISS index built with {faiss_index.ntotal} vectors.\")\n",
        "\n",
        "# 3. Build Sparse Index (BM25)\n",
        "tokenized_corpus = [doc.lower().split(\" \") for doc in chunk_texts]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "print(\"BM25 index built.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvdVUFWRGdCk"
      },
      "source": [
        "**2.3 Hybrid Retrieval Pipeline**\n",
        "\n",
        "Our retrieval pipeline will combine the strengths of both dense and sparse methods. For a given query, we will:\n",
        "1. Preprocess the query.\n",
        "2. Retrieve the top N chunks from FAISS based on vector similarity.\n",
        "3. Retrieve the top N chunks from BM25 based on keyword matching.\n",
        "4. Combine the results using a simple union to create a comprehensive list of candidate chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "leXIMB6fGdCk"
      },
      "outputs": [],
      "source": [
        "def preprocess_query(query):\n",
        "    # Normalize\n",
        "    query = query.lower()\n",
        "\n",
        "    # All the queries are about Kyndryl. So, let's remove that, it might bias the retriever\n",
        "    # Remove redundant keywords\n",
        "    stopwords = [\"kyndryl\", \"IBM\", \"company\", \"inc\", \"inc.\", \"corporation\", \"corp\", \"corp.\", \"ltd\", \"ltd.\", \"plc\", \"the\"]\n",
        "    for w in stopwords:\n",
        "        query = query.replace(w.lower(), \"\")\n",
        "    return query.strip()\n",
        "\n",
        "def hybrid_retrieve(query, top_n=5):\n",
        "    # 1. Preprocess query\n",
        "    clean_query = preprocess_query(query)\n",
        "\n",
        "    # 2. Dense Retrieval (FAISS)\n",
        "    query_embedding = embedding_model.encode([clean_query])\n",
        "    _, dense_indices = faiss_index.search(np.array(query_embedding, dtype=np.float32), top_n)\n",
        "    dense_results = [all_chunks[i] for i in dense_indices[0]]\n",
        "\n",
        "    # 3. Sparse Retrieval (BM25)\n",
        "    tokenized_query = clean_query.split(\" \")\n",
        "    bm25_scores = bm25.get_scores(tokenized_query)\n",
        "    sparse_indices = np.argsort(bm25_scores)[::-1][:top_n]\n",
        "    sparse_results = [all_chunks[i] for i in sparse_indices]\n",
        "\n",
        "    # 4. Combine results\n",
        "    combined_results_dict = {chunk['id']: chunk for chunk in dense_results + sparse_results}\n",
        "\n",
        "    print(f\"Retrieved {len(dense_results)} chunks from dense search.\")\n",
        "    print(f\"Retrieved {len(sparse_results)} chunks from sparse search.\")\n",
        "    print(f\"Combined to {len(combined_results_dict)} unique chunks.\")\n",
        "\n",
        "    return list(combined_results_dict.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "echsdYb4GdCk",
        "outputId": "d825478f-4434-4270-d02f-72e1c8d0c5cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 10 unique chunks.\n",
            "\n",
            "--- Top Retrieved Chunk for 'What was the company's revenue in 2024?' ---\n",
            "q : revenues of 2024? a : $ 16, 052 million.\n"
          ]
        }
      ],
      "source": [
        "# Example Usage\n",
        "test_query = \"What was the company's revenue in 2024?\"\n",
        "retrieved_chunks = hybrid_retrieve(test_query)\n",
        "\n",
        "print(f\"\\n--- Top Retrieved Chunk for '{test_query}' ---\")\n",
        "print(retrieved_chunks[0]['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85BY6bLzGdCk"
      },
      "source": [
        "**2.4 Advanced RAG Technique: Cross-Encoder Re-ranking**\n",
        "\n",
        "The initial retrieval might return chunks that are only partially relevant. To refine our results, we'll use a Cross-Encoder model. Unlike the embedding model which computes vectors independently, a Cross-Encoder takes both the query and a candidate chunk as input to produce a more accurate relevance score. We will use this to re-rank the top chunks retrieved from our hybrid pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mbiRXVHHGdCk"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers.cross_encoder import CrossEncoder\n",
        "\n",
        "# Load a cross-encoder model\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "def rerank_with_cross_encoder(query, chunks):\n",
        "    # Create pairs of [query, chunk_text] for scoring\n",
        "    query_chunk_pairs = [[query, chunk['text']] for chunk in chunks]\n",
        "\n",
        "    # Get scores from the cross-encoder\n",
        "    scores = cross_encoder.predict(query_chunk_pairs, show_progress_bar=False)\n",
        "\n",
        "    # Add scores to chunks and sort\n",
        "    for i in range(len(chunks)):\n",
        "        chunks[i]['relevance_score'] = scores[i]\n",
        "\n",
        "    reranked_chunks = sorted(chunks, key=lambda x: x['relevance_score'], reverse=True)\n",
        "    return reranked_chunks\n",
        "\n",
        "\n",
        "def advanced_retrieve(query):\n",
        "    retrieved_chunks = hybrid_retrieve(query)\n",
        "    reranked_results = rerank_with_cross_encoder(query, retrieved_chunks)\n",
        "    return reranked_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTwUsa3mGdCk",
        "outputId": "9af58a41-8dfe-46fe-debc-2b2d3a4b38dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 10 unique chunks.\n",
            "\n",
            "--- Top Re-ranked Chunk for 'What was the company's revenue in 2024?' ---\n",
            "Relevance Score: 8.9147\n",
            "q : revenues of 2024? a : $ 16, 052 million.\n"
          ]
        }
      ],
      "source": [
        "# Example Usage with the same test query\n",
        "test_query = \"What was the company's revenue in 2024?\"\n",
        "reranked_results = advanced_retrieve(test_query)\n",
        "print(f\"\\n--- Top Re-ranked Chunk for '{test_query}' ---\")\n",
        "print(f\"Relevance Score: {reranked_results[0]['relevance_score']:.4f}\")\n",
        "print(reranked_results[0]['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGVWiCa7GdCk"
      },
      "source": [
        "**2.5 Response Generation**\n",
        "\n",
        "After retrieving and re-ranking the most relevant document chunks, the final step is to generate a coherent, human-readable answer. We will use a generative language model to synthesize the information from the retrieved passages into a direct response to the user's query.\n",
        "\n",
        "For this demonstration, we'll use `Flan T5`, a smaller and more efficient version, which is suitable for tasks where resource constraints are a consideration. The retrieved text and the original query are combined into a carefully crafted prompt to guide the model in generating a factual answer grounded in the provided context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z0xOG6sGdCk",
        "outputId": "b3749a51-900c-473a-e3f1-d706b3986e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
        "\n",
        "# --- Configuration ---\n",
        "# Using google/flan-t5-base is a good balance for an 8GB M2 Mac.\n",
        "# 'small' is faster but less accurate; 'large' may run out of memory.\n",
        "model_name = \"google/flan-t5-base\"\n",
        "\n",
        "# --- Model and Tokenizer Loading ---\n",
        "# Load the model and tokenizer, sending the model to the specified device\n",
        "try:\n",
        "    gen_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    gen_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    print(\"Please ensure you have a stable internet connection.\")\n",
        "    exit()\n",
        "\n",
        "# --- Initialize Pipeline ---\n",
        "# Initialize the pipeline once for efficiency, specifying the correct task and device\n",
        "# For MPS, device=0 is the standard way to reference the first MPS device.\n",
        "nlp_pipeline = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=gen_model,\n",
        "    tokenizer=gen_tokenizer,\n",
        ")\n",
        "\n",
        "def generate_answer(query, reranked_chunks, max_new_tokens=100):\n",
        "    \"\"\"\n",
        "    Generates an answer using the Flan-T5 model based on the retrieved chunks.\n",
        "    \"\"\"\n",
        "    # 1. Prepare the context from the top 3 reranked chunks\n",
        "    context = \"\\n\\n\".join([chunk.get(\"text\", \"\") for chunk in reranked_chunks[:3]])\n",
        "\n",
        "    # 2. Create a prompt suitable for Flan-T5\n",
        "    # This instruction-based format works well for this model family.\n",
        "    prompt = f\"\"\"\n",
        "Based on the following context, please answer the question.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "    # 3. Generate the answer using the pre-initialized pipeline\n",
        "    # The pipeline handles tokenization, truncation, and moving data to the MPS device.\n",
        "    generated_output = nlp_pipeline(\n",
        "        prompt,\n",
        "        max_length=512,  # Set a max_length for the input+output\n",
        "        max_new_tokens=max_new_tokens,  # Control the max length of the generated answer\n",
        "        num_return_sequences=1,\n",
        "    )\n",
        "\n",
        "    # 4. Extract and clean the answer text\n",
        "    # The output from a 'text2text-generation' pipeline is cleaner.\n",
        "    answer = generated_output[0][\"generated_text\"].strip()\n",
        "\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzmIyC3UGdCk",
        "outputId": "3870026d-8a36-45ea-b88d-51bc6823e1cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=100) and `max_length`(=512) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is fiscal year 2024 revenue?\n",
            "Retrieved 5 chunks from dense search.\n",
            "Retrieved 5 chunks from sparse search.\n",
            "Combined to 10 unique chunks.\n",
            "\n",
            "Generated Answer:\n",
            "$ 16, 052 million\n"
          ]
        }
      ],
      "source": [
        "def query_finance_system_rag(query, debug = False):\n",
        "    reranked_results = advanced_retrieve(query)\n",
        "\n",
        "    if debug:\n",
        "        for r in reranked_results:\n",
        "            print('-----')\n",
        "            print(r['text'])\n",
        "\n",
        "    # Example Usage\n",
        "    final_answer = generate_answer(query, reranked_results)\n",
        "    return final_answer\n",
        "\n",
        "test_query = \"What is fiscal year 2024 revenue?\"\n",
        "print(f\"Question: {test_query}\")\n",
        "final_answer = query_finance_system_rag(test_query)\n",
        "print(f\"\\nGenerated Answer:\\n{final_answer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybP7XhyAGdCk"
      },
      "source": [
        "**2.6 Guardrail Implementation**\n",
        "\n",
        "To ensure the reliability and safety of our RAG system, we need to implement guardrails. These are checks and balances that prevent the system from processing inappropriate queries or generating harmful, irrelevant, or factually incorrect answers. We will implement two basic guardrails:\n",
        "\n",
        "1.  **Input Guardrail:** A simple filter to block off-topic or nonsensical questions.\n",
        "2.  **Output Guardrail:** A check to ensure the generated answer is grounded in the retrieved context and not a hallucination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKLRUEoUGdCl",
        "outputId": "a2e3058d-3cc8-4e83-8bd8-39321e587149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Input Guardrail Tests ---\n",
            "Query: 'What were the total assets of Kyndryl as of March 31, 2024?' -> Valid: True, Reason: Query is valid.\n",
            "Query: 'revenue?' -> Valid: False, Reason: Query is too short. Please ask a more specific question.\n",
            "Query: 'Can you give me a recipe for a cake?' -> Valid: False, Reason: Query is off-topic. This system is for financial document analysis.\n",
            "\n",
            "==================================================\n",
            "\n",
            "--- Output Guardrail Tests ---\n",
            "Answer: '$ 16, 052 million...' -> Grounded: True, Reason: Answer appears grounded in context (Overlap: 75.00%).\n",
            "Answer: 'Kyndryl announced a partnership with SpaceX to build datacenters on Mars.' -> Grounded: False, Reason: Potential hallucination detected. Answer may not be grounded in context (Overlap: 9.09%).\n"
          ]
        }
      ],
      "source": [
        "# --- Input Guardrail ---\n",
        "\n",
        "def validate_query(query):\n",
        "    \"\"\"\n",
        "    Validates the input query to filter out irrelevant or harmful inputs.\n",
        "    \"\"\"\n",
        "    query = query.lower()\n",
        "\n",
        "    # Check for minimum length\n",
        "    if len(query.split()) < 3:\n",
        "        return False, \"Query is too short. Please ask a more specific question.\"\n",
        "\n",
        "    # Basic check for off-topic keywords\n",
        "    off_topic_keywords = ['recipe', 'poem', 'joke', 'movie', 'celebrity']\n",
        "    if any(keyword in query for keyword in off_topic_keywords):\n",
        "        return False, \"Query is off-topic. This system is for financial document analysis.\"\n",
        "\n",
        "    return True, \"Query is valid.\"\n",
        "\n",
        "# --- Output Guardrail ---\n",
        "\n",
        "def validate_output(answer, retrieved_chunks):\n",
        "    \"\"\"\n",
        "    Validates the generated output to flag potential hallucinations.\n",
        "    This is a simple check based on keyword overlap.\n",
        "    \"\"\"\n",
        "    context = \" \".join([chunk['text'].lower() for chunk in retrieved_chunks])\n",
        "    answer_tokens = set(answer.lower().split())\n",
        "    context_tokens = set(context.split())\n",
        "\n",
        "    if not answer_tokens:\n",
        "        return False, \"Generated answer is empty.\"\n",
        "\n",
        "    # Calculate the percentage of answer tokens that are present in the context\n",
        "    overlap = answer_tokens.intersection(context_tokens)\n",
        "    overlap_ratio = len(overlap) / len(answer_tokens)\n",
        "\n",
        "    # If overlap is less than a certain threshold (e.g., 30%), flag it as potentially ungrounded.\n",
        "    if overlap_ratio < 0.3:\n",
        "        return False, f\"Potential hallucination detected. Answer may not be grounded in context (Overlap: {overlap_ratio:.2%}).\"\n",
        "\n",
        "    return True, f\"Answer appears grounded in context (Overlap: {overlap_ratio:.2%}).\"\n",
        "\n",
        "\n",
        "# --- Example Usage of Guardrails ---\n",
        "\n",
        "# 1. Input Guardrail Examples\n",
        "print(\"--- Input Guardrail Tests ---\")\n",
        "valid_query = \"What were the total assets of Kyndryl as of March 31, 2024?\"\n",
        "invalid_query_short = \"revenue?\"\n",
        "invalid_query_topic = \"Can you give me a recipe for a cake?\"\n",
        "\n",
        "is_valid, reason = validate_query(valid_query)\n",
        "print(f\"Query: '{valid_query}' -> Valid: {is_valid}, Reason: {reason}\")\n",
        "\n",
        "is_valid, reason = validate_query(invalid_query_short)\n",
        "print(f\"Query: '{invalid_query_short}' -> Valid: {is_valid}, Reason: {reason}\")\n",
        "\n",
        "is_valid, reason = validate_query(invalid_query_topic)\n",
        "print(f\"Query: '{invalid_query_topic}' -> Valid: {is_valid}, Reason: {reason}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# 2. Output Guardrail Example\n",
        "print(\"--- Output Guardrail Tests ---\")\n",
        "# Use the previously generated answer\n",
        "is_grounded, reason = validate_output(final_answer, reranked_results)\n",
        "print(f\"Answer: '{final_answer[:100]}...' -> Grounded: {is_grounded}, Reason: {reason}\")\n",
        "\n",
        "# Example of a potentially hallucinated answer\n",
        "hallucinated_answer = \"Kyndryl announced a partnership with SpaceX to build datacenters on Mars.\"\n",
        "is_grounded, reason = validate_output(hallucinated_answer, reranked_results)\n",
        "print(f\"Answer: '{hallucinated_answer}' -> Grounded: {is_grounded}, Reason: {reason}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4z5UyPMGdCl"
      },
      "source": [
        "### 3. Fine-Tuned Model System Implementation\n",
        "\n",
        "\n",
        "#### 3.1 Q/A Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwuQTbCwGdCl",
        "outputId": "8d239c61-24f4-4781-fa25-ac98a8b40322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'question: Total liabilities of 2023? answer: $ 10,002 million.'}\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Convert to a list of dictionaries for the dataset\n",
        "fine_tuning_data = []\n",
        "for doc_id, questions in qa_documents.items():\n",
        "    fine_tuning_data.extend(\n",
        "        [\n",
        "            {\"text\": f\"question: {question} answer: {answer}\"}\n",
        "            for question, answer in questions\n",
        "        ]\n",
        "    )\n",
        "\n",
        "df = pd.DataFrame(fine_tuning_data)\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "\n",
        "print(dataset[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-WcFHs7GdCl"
      },
      "source": [
        "#### 3.2 Model Selection\n",
        "\n",
        "we will use the google/flan-t5-base model as RAG setup. This is a versatile and powerful model that is well-suited for a variety of NLP tasks, including question answering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "o0-xrvfqGdCl"
      },
      "outputs": [],
      "source": [
        "model_name = 'google/flan-t5-base'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scNvO87JGdCl"
      },
      "source": [
        "### 3.3 Fine-Tuning\n",
        "Now we will fine-tune the selected model on our prepared Q/A dataset. We will use the transformers library from Hugging Face for this task. We'll also log the hyperparameters used in the training process.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571,
          "referenced_widgets": [
            "0c6c69330e264a6b81a22c836a19d735",
            "271c8c583e7040598393972740521201",
            "0c00b1c1fac947f6b9fcf31e4dc8c420",
            "12740e0ff0d3486f9fb336ebd1a5613f",
            "45083e67ee9840e1b1137f3df88c5e30",
            "223d52fdf686452f98e32bc15972e95a",
            "b21a431f14ea433c8c9c0f24fb33eaf8",
            "0de7cc86102b47cdb8526eae49e70cd5",
            "1e9296f7f7134054b91fa7cf50bfad43",
            "4c974d5780bf429cbf5fcc1894ee2e81",
            "038b5ff2c2f94be3b5949b0f011fdc9e"
          ]
        },
        "id": "J8nzYZGwGdCl",
        "outputId": "826373d8-05c2-49aa-d589-2281057c5cb1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/118 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c6c69330e264a6b81a22c836a19d735"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters:\n",
            "  Learning Rate: 2e-05\n",
            "  Batch Size: 8\n",
            "  Number of Epochs: 3\n",
            "  Compute Setup: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1283009621.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n",
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjawaharbtech\u001b[0m (\u001b[33mjawahar-s\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250823_181028-ixd5ud74</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jawahar-s/huggingface/runs/ixd5ud74' target=\"_blank\">fast-smoke-1</a></strong> to <a href='https://wandb.ai/jawahar-s/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jawahar-s/huggingface' target=\"_blank\">https://wandb.ai/jawahar-s/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jawahar-s/huggingface/runs/ixd5ud74' target=\"_blank\">https://wandb.ai/jawahar-s/huggingface/runs/ixd5ud74</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [45/45 00:45, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=45, training_loss=25.12275390625, metrics={'train_runtime': 203.0731, 'train_samples_per_second': 1.743, 'train_steps_per_second': 0.222, 'total_flos': 60601025691648.0, 'train_loss': 25.12275390625, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
        "import torch\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Preprocess the dataset\n",
        "def preprocess_function(examples):\n",
        "    inputs = [ex for ex in examples[\"text\"]]\n",
        "    # The model expects 'labels' for the target text\n",
        "    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # The T5 model needs the decoder input_ids to be created from the labels\n",
        "    # The Trainer does this automatically if the 'labels' field is present.\n",
        "    # We just need to make sure our tokenized outputs have a 'labels' key.\n",
        "    # For T5, the input and output are the same text sequence for this task.\n",
        "    model_inputs[\"labels\"] = model_inputs[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Define the training arguments\n",
        "# NOTE: The 'evaluation_strategy' and 'device' arguments have been removed.\n",
        "# 'do_eval=True' enables evaluation, which defaults to the end of each epoch.\n",
        "# The Trainer will automatically use the GPU if it's available.\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    do_eval=True,  # Enable evaluation\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "# Log the hyperparameters\n",
        "print(\"Hyperparameters:\")\n",
        "print(f\"  Learning Rate: {training_args.learning_rate}\")\n",
        "print(f\"  Batch Size: {training_args.per_device_train_batch_size}\")\n",
        "print(f\"  Number of Epochs: {training_args.num_train_epochs}\")\n",
        "\n",
        "# Determine compute setup and log it\n",
        "compute_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"  Compute Setup: {compute_device}\")\n",
        "\n",
        "\n",
        "# Create the data collator\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    eval_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Start fine-tuning\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n--- Testing the Fine-Tuned Model from Section 3.3 ---\")\n",
        "\n",
        "# Save the final model\n",
        "trainer.save_model(\"./results_s3_3/final_model\")\n",
        "\n",
        "# Load the fine-tuned model from the checkpoint\n",
        "fine_tuned_model_3_3 = AutoModelForSeq2SeqLM.from_pretrained(\"./results_s3_3/final_model\")\n",
        "fine_tuned_model_3_3.to(compute_device)\n",
        "\n",
        "def ask_simple_finetuned_model(question):\n",
        "    # We must match the prompt format that the model was trained on\n",
        "    prompt = f\"question: {question} answer:\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(compute_device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = fine_tuned_model_3_3.generate(**inputs, max_new_tokens=50)\n",
        "\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return answer\n",
        "\n",
        "# --- Prediction and Analysis ---\n",
        "test_question = \"Total assets of 2023?\"\n",
        "predicted_answer = ask_simple_finetuned_model(test_question)\n",
        "\n",
        "print(f\"\\nQ: {test_question}\")\n",
        "print(f\"A: {predicted_answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqF4IptJWfBp",
        "outputId": "655c8144-7e86-43bc-a9c9-7ff934e9954f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing the Fine-Tuned Model from Section 3.3 ---\n",
            "\n",
            "Q: Total assets of 2023?\n",
            "A: 2 billion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaNjQgjFGdCl"
      },
      "source": [
        "#### 3.4 Advanced Fine-Tuning Technique (Mixture-of-Experts Fine-Tuning)\n",
        "\n",
        "We will create two specialized experts:\n",
        "\n",
        "Expert A: The \"Balance Sheet\" Expert: This expert will be a specialist on questions related to a company's assets and liabilities. These items reflect a company's financial position at a single point in time (e.g., \"as of March 31, 2023\").\n",
        "\n",
        "Expert B: The \"Income Statement\" Expert: This expert will specialize in questions about revenues, costs, and expenses. These items reflect a company's performance over a period of time (e.g., \"for the year 2024\").\n",
        "\n",
        "\n",
        "#### Step 1: Prepare and Split the Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "# Assuming qa_documents is defined as before (with list of tuples)\n",
        "\n",
        "# --- Data Preparation ---\n",
        "balance_sheet_q = []\n",
        "balance_sheet_a = []\n",
        "income_statement_q = []\n",
        "income_statement_a = []\n",
        "\n",
        "# Iterate and populate separate lists for questions and answers\n",
        "for key, qa_list_of_tuples in qa_documents.items():\n",
        "    for question,answer  in qa_list_of_tuples:\n",
        "        if 'Balance Sheet' in key:\n",
        "            balance_sheet_q.append(question)\n",
        "            balance_sheet_a.append(answer)\n",
        "        elif 'Income Statement' in key:\n",
        "            income_statement_q.append(question)\n",
        "            income_statement_a.append(answer)\n",
        "\n",
        "# Create DataFrames with separate columns\n",
        "df_balance_sheet = pd.DataFrame({'question': balance_sheet_q, 'answer': balance_sheet_a})\n",
        "df_income_statement = pd.DataFrame({'question': income_statement_q, 'answer': income_statement_a})\n",
        "\n",
        "# Create Hugging Face Datasets\n",
        "balance_sheet_dataset = Dataset.from_pandas(df_balance_sheet)\n",
        "income_statement_dataset = Dataset.from_pandas(df_income_statement)\n",
        "\n",
        "print(\"--- Balance Sheet Dataset (Expert A) ---\")\n",
        "print(balance_sheet_dataset[0])\n",
        "\n",
        "\n",
        "# --- Corrected Preprocessing Function ---\n",
        "# This is the most critical change.\n",
        "def preprocess_seq2seq(examples):\n",
        "    # Tokenize the questions (inputs)\n",
        "    model_inputs = tokenizer(examples['question'], max_length=128, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Tokenize the answers (labels)\n",
        "    labels = tokenizer(text_target=examples['answer'], max_length=50, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # The 'labels' field is what the model will learn to predict\n",
        "    model_inputs['labels'] = labels['input_ids']\n",
        "    return model_inputs\n",
        "\n",
        "# Apply the new preprocessing function\n",
        "# Assumes 'tokenizer' is already loaded\n",
        "tokenized_balance_sheet_dataset = balance_sheet_dataset.map(preprocess_seq2seq, batched=True)\n",
        "tokenized_income_statement_dataset = income_statement_dataset.map(preprocess_seq2seq, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "c977fa9155344791b4ddd7759b94b821",
            "4456c458485c49b6853f18860289bbde",
            "1076b7413e0b4879a748bbab4b04e2ca",
            "53bd4eabfdb54b18b8c94e4c74acec95",
            "65e5e4ab924e4f05a3a4e07eb1da79c3",
            "f578fafb28c84f7ab5b1f99142029441",
            "b202f4894a524b6b820c255c8d8c3f7c",
            "770d2f90e51548e8b3228b4b5ccd5a3b",
            "8abf45f28f8e4d36a33d22e01a89f32d",
            "7bf51213aa8a412384bbfce72ab4b08f",
            "40ddd0eb8c314f25b26819dfc44cb578",
            "378aee5ffe29425fb8b7c1a770f07381",
            "21ceb84030284f40b6cf1d3a23dd2e3c",
            "b8640bd2234e44548eacba900daf75d8",
            "b054abc048864574ab70054f5e996d9b",
            "2803a1365caf4130bfad2ecc23a4dec3",
            "03d2be8f3d3848d1879922bde06d7126",
            "30863ab3812a4513a7b516f110af18da",
            "084d73fb2fe54aceafa25d89de980fba",
            "1376084b3dd54de080eeb790d590f07a",
            "b3f13d2820a54ba48530545fea2cc55c",
            "12b70de5211544b0a320cb93e10dd638"
          ]
        },
        "id": "1YyQOpUfNE4Q",
        "outputId": "dbae6387-caf9-468b-b3eb-6e9eae6714f9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Balance Sheet Dataset (Expert A) ---\n",
            "{'question': 'Cash and cash equivalents assets of 2024?', 'answer': '$ 1,553 million.'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/52 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c977fa9155344791b4ddd7759b94b821"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/66 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "378aee5ffe29425fb8b7c1a770f07381"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2: Train the Two Expert LoRA Adapters\n"
      ],
      "metadata": {
        "id": "e6sP4_0ZOvbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "dir_balance_sheet = './lora_expert_balance_sheet'\n",
        "dir_income_statement = './lora_expert_income_statement'\n",
        "\n",
        "if os.path.exists(dir_balance_sheet):\n",
        "    shutil.rmtree(dir_balance_sheet)\n",
        "    print(f\"Deleted old directory: {dir_balance_sheet}\")\n",
        "\n",
        "if os.path.exists(dir_income_statement):\n",
        "    shutil.rmtree(dir_income_statement)\n",
        "    print(f\"Deleted old directory: {dir_income_statement}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D19r7mB1RtGe",
        "outputId": "3d093455-adbb-4d34-d9b2-1539e30638ab"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted old directory: ./lora_expert_balance_sheet\n",
            "Deleted old directory: ./lora_expert_income_statement\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# --- Reusable Setup ---\n",
        "model_name = 'google/flan-t5-base'\n",
        "# Assumes 'tokenizer' is loaded from data prep step\n",
        "\n",
        "# We give the model more capacity to learn the facts.\n",
        "lora_config = LoraConfig(\n",
        "    r=32,                  # <-- INCREASED RANK from 16 to 32\n",
        "    lora_alpha=64,           # <-- INCREASED ALPHA from 32 to 64 (common practice is 2*r)\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name)\n",
        "\n",
        "# --- Train Expert A (Balance Sheet) ---\n",
        "print(\"\\n--- Starting INTENSIVE Training for Expert A (Balance Sheet) ---\")\n",
        "balance_sheet_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "balance_sheet_peft_model = get_peft_model(balance_sheet_model, lora_config)\n",
        "balance_sheet_peft_model.print_trainable_parameters()\n",
        "\n",
        "balance_sheet_training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./lora_expert_balance_sheet\",\n",
        "    num_train_epochs=200,      # <-- MASSIVELY INCREASED EPOCHS (was 75)\n",
        "    learning_rate=1e-4,        # <-- Adjusted Learning Rate\n",
        "    per_device_train_batch_size=4,\n",
        "    weight_decay=0.01,\n",
        "    lr_scheduler_type='cosine', # <-- Added a learning rate scheduler for stability\n",
        "    logging_strategy=\"epoch\",  # <-- Log loss every epoch to watch for convergence\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "balance_sheet_trainer = Seq2SeqTrainer(\n",
        "    model=balance_sheet_peft_model,\n",
        "    args=balance_sheet_training_args,\n",
        "    train_dataset=tokenized_balance_sheet_dataset, # Assumes this is correctly loaded\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "balance_sheet_trainer.train()\n",
        "balance_sheet_trainer.model.save_pretrained(\"./lora_expert_balance_sheet\")\n",
        "print(\"Expert A (Balance Sheet) adapter saved.\")\n",
        "\n",
        "\n",
        "# --- Train Expert B (Income Statement) ---\n",
        "print(\"\\n--- Starting INTENSIVE Training for Expert B (Income Statement) ---\")\n",
        "income_statement_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "income_statement_peft_model = get_peft_model(income_statement_model, lora_config)\n",
        "\n",
        "# Use the same aggressive arguments for the second expert\n",
        "income_statement_training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./lora_expert_income_statement\",\n",
        "    num_train_epochs=200,      # <-- MASSIVELY INCREASED EPOCHS\n",
        "    learning_rate=1e-4,        # <-- Adjusted Learning Rate\n",
        "    per_device_train_batch_size=4,\n",
        "    weight_decay=0.01,\n",
        "    lr_scheduler_type='cosine', # <-- Added a learning rate scheduler\n",
        "    logging_strategy=\"epoch\",\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "income_statement_trainer = Seq2SeqTrainer(\n",
        "    model=income_statement_peft_model,\n",
        "    args=income_statement_training_args,\n",
        "    train_dataset=tokenized_income_statement_dataset, # Assumes this is correctly loaded\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "income_statement_trainer.train()\n",
        "income_statement_trainer.model.save_pretrained(\"./lora_expert_income_statement\")\n",
        "print(\"Expert B (Income Statement) adapter saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oLfjbaFROxHW",
        "outputId": "48d1c0dd-00a9-4726-f9c6-15bf761b4eff"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting INTENSIVE Training for Expert A (Balance Sheet) ---\n",
            "trainable params: 3,538,944 || all params: 251,116,800 || trainable%: 1.4093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3284279399.py:37: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  balance_sheet_trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2600' max='2600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2600/2600 07:42, Epoch 200/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>36.309900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>32.167500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>26.770200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>21.314300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>14.793500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>7.631800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>5.411900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>4.810800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>4.418100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>4.099900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>143</td>\n",
              "      <td>3.710200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>3.181400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>169</td>\n",
              "      <td>2.787700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>182</td>\n",
              "      <td>2.467600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>2.193000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>208</td>\n",
              "      <td>1.865100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>221</td>\n",
              "      <td>1.632400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>1.379700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>247</td>\n",
              "      <td>1.223700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>1.069600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>273</td>\n",
              "      <td>0.928600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>286</td>\n",
              "      <td>1.050100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>299</td>\n",
              "      <td>0.787600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>312</td>\n",
              "      <td>0.710200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>0.637900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>338</td>\n",
              "      <td>0.593400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>351</td>\n",
              "      <td>0.539700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>364</td>\n",
              "      <td>0.513300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>377</td>\n",
              "      <td>0.478600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.448900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>403</td>\n",
              "      <td>0.433300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>416</td>\n",
              "      <td>0.408400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>429</td>\n",
              "      <td>0.396100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>442</td>\n",
              "      <td>0.383100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>455</td>\n",
              "      <td>0.382900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>0.359400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>481</td>\n",
              "      <td>0.349200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>494</td>\n",
              "      <td>0.340200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>507</td>\n",
              "      <td>0.320100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.323500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>533</td>\n",
              "      <td>0.325500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>546</td>\n",
              "      <td>0.316700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>559</td>\n",
              "      <td>0.307700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>572</td>\n",
              "      <td>0.299900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>585</td>\n",
              "      <td>0.290400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>598</td>\n",
              "      <td>0.276000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>611</td>\n",
              "      <td>0.285600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>624</td>\n",
              "      <td>0.285700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>637</td>\n",
              "      <td>0.276700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.264100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>663</td>\n",
              "      <td>0.260800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>676</td>\n",
              "      <td>0.259800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>689</td>\n",
              "      <td>0.258000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>702</td>\n",
              "      <td>0.259400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>715</td>\n",
              "      <td>0.257600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>728</td>\n",
              "      <td>0.249400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>741</td>\n",
              "      <td>0.243500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>754</td>\n",
              "      <td>0.245600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>767</td>\n",
              "      <td>0.253600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.244200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>793</td>\n",
              "      <td>0.235900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>806</td>\n",
              "      <td>0.238600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>819</td>\n",
              "      <td>0.233700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>832</td>\n",
              "      <td>0.235200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>845</td>\n",
              "      <td>0.238500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>858</td>\n",
              "      <td>0.224900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>871</td>\n",
              "      <td>0.224700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>884</td>\n",
              "      <td>0.222500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>897</td>\n",
              "      <td>0.227700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.230000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>923</td>\n",
              "      <td>0.219400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>936</td>\n",
              "      <td>0.216700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>949</td>\n",
              "      <td>0.220700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>962</td>\n",
              "      <td>0.211400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>975</td>\n",
              "      <td>0.214700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>988</td>\n",
              "      <td>0.210700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1001</td>\n",
              "      <td>0.214000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1014</td>\n",
              "      <td>0.209400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1027</td>\n",
              "      <td>0.205900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.209000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1053</td>\n",
              "      <td>0.210700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1066</td>\n",
              "      <td>0.201600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1079</td>\n",
              "      <td>0.207400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1092</td>\n",
              "      <td>0.212400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1105</td>\n",
              "      <td>0.201400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1118</td>\n",
              "      <td>0.204700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1131</td>\n",
              "      <td>0.202000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1144</td>\n",
              "      <td>0.202500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1157</td>\n",
              "      <td>0.204700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.204600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1183</td>\n",
              "      <td>0.202600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1196</td>\n",
              "      <td>0.195700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1209</td>\n",
              "      <td>0.198900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1222</td>\n",
              "      <td>0.200500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1235</td>\n",
              "      <td>0.202300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1248</td>\n",
              "      <td>0.186000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1261</td>\n",
              "      <td>0.193800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1274</td>\n",
              "      <td>0.189500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1287</td>\n",
              "      <td>0.197100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.196500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1313</td>\n",
              "      <td>0.186700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1326</td>\n",
              "      <td>0.188800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1339</td>\n",
              "      <td>0.190500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1352</td>\n",
              "      <td>0.193600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1365</td>\n",
              "      <td>0.187900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1378</td>\n",
              "      <td>0.182400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1391</td>\n",
              "      <td>0.190200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1404</td>\n",
              "      <td>0.185200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1417</td>\n",
              "      <td>0.181300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1430</td>\n",
              "      <td>0.184500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1443</td>\n",
              "      <td>0.176800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1456</td>\n",
              "      <td>0.188200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1469</td>\n",
              "      <td>0.184300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1482</td>\n",
              "      <td>0.184800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1495</td>\n",
              "      <td>0.180100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1508</td>\n",
              "      <td>0.179500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1521</td>\n",
              "      <td>0.182500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1534</td>\n",
              "      <td>0.177700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1547</td>\n",
              "      <td>0.170900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>0.186300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1573</td>\n",
              "      <td>0.183800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1586</td>\n",
              "      <td>0.184100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1599</td>\n",
              "      <td>0.178300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1612</td>\n",
              "      <td>0.176600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1625</td>\n",
              "      <td>0.176700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1638</td>\n",
              "      <td>0.172100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1651</td>\n",
              "      <td>0.177400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1664</td>\n",
              "      <td>0.174700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1677</td>\n",
              "      <td>0.177700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1690</td>\n",
              "      <td>0.175300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1703</td>\n",
              "      <td>0.170500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1716</td>\n",
              "      <td>0.180800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1729</td>\n",
              "      <td>0.176000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1742</td>\n",
              "      <td>0.168000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1755</td>\n",
              "      <td>0.171900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1768</td>\n",
              "      <td>0.167800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1781</td>\n",
              "      <td>0.176300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1794</td>\n",
              "      <td>0.168300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1807</td>\n",
              "      <td>0.171000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1820</td>\n",
              "      <td>0.173100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1833</td>\n",
              "      <td>0.167800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1846</td>\n",
              "      <td>0.168000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1859</td>\n",
              "      <td>0.167600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1872</td>\n",
              "      <td>0.171700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1885</td>\n",
              "      <td>0.165800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1898</td>\n",
              "      <td>0.167800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1911</td>\n",
              "      <td>0.168700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1924</td>\n",
              "      <td>0.166700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1937</td>\n",
              "      <td>0.170100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.175000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1963</td>\n",
              "      <td>0.166300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1976</td>\n",
              "      <td>0.167200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1989</td>\n",
              "      <td>0.173500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2002</td>\n",
              "      <td>0.170100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2015</td>\n",
              "      <td>0.169400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2028</td>\n",
              "      <td>0.165700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2041</td>\n",
              "      <td>0.163900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2054</td>\n",
              "      <td>0.164900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2067</td>\n",
              "      <td>0.164200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2080</td>\n",
              "      <td>0.159400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2093</td>\n",
              "      <td>0.170300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2106</td>\n",
              "      <td>0.169500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2119</td>\n",
              "      <td>0.167400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2132</td>\n",
              "      <td>0.167800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2145</td>\n",
              "      <td>0.166800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2158</td>\n",
              "      <td>0.164900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2171</td>\n",
              "      <td>0.165600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2184</td>\n",
              "      <td>0.165700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2197</td>\n",
              "      <td>0.162900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2210</td>\n",
              "      <td>0.161900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2223</td>\n",
              "      <td>0.157700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2236</td>\n",
              "      <td>0.167300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2249</td>\n",
              "      <td>0.159600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2262</td>\n",
              "      <td>0.163100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2275</td>\n",
              "      <td>0.169700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2288</td>\n",
              "      <td>0.163400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2301</td>\n",
              "      <td>0.164200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2314</td>\n",
              "      <td>0.160300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2327</td>\n",
              "      <td>0.163000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.164700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2353</td>\n",
              "      <td>0.167500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2366</td>\n",
              "      <td>0.167700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2379</td>\n",
              "      <td>0.162200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2392</td>\n",
              "      <td>0.161100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2405</td>\n",
              "      <td>0.166500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2418</td>\n",
              "      <td>0.160200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2431</td>\n",
              "      <td>0.168500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2444</td>\n",
              "      <td>0.163900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2457</td>\n",
              "      <td>0.166900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2470</td>\n",
              "      <td>0.164300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2483</td>\n",
              "      <td>0.165100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2496</td>\n",
              "      <td>0.163600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2509</td>\n",
              "      <td>0.167500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2522</td>\n",
              "      <td>0.169400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2535</td>\n",
              "      <td>0.164600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2548</td>\n",
              "      <td>0.158000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2561</td>\n",
              "      <td>0.170200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2574</td>\n",
              "      <td>0.163800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2587</td>\n",
              "      <td>0.160800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.163300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expert A (Balance Sheet) adapter saved.\n",
            "\n",
            "--- Starting INTENSIVE Training for Expert B (Income Statement) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3284279399.py:66: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  income_statement_trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3400' max='3400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3400/3400 10:07, Epoch 200/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>36.984900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>30.868400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>24.745600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>17.214600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>8.153900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>5.356600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>4.730500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136</td>\n",
              "      <td>4.336700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>4.005100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>3.446900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>187</td>\n",
              "      <td>2.857100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>204</td>\n",
              "      <td>2.439500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>221</td>\n",
              "      <td>1.974100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>238</td>\n",
              "      <td>1.618900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>1.291400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>272</td>\n",
              "      <td>1.064800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>289</td>\n",
              "      <td>0.928100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>306</td>\n",
              "      <td>0.764500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>323</td>\n",
              "      <td>0.698900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.596600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>357</td>\n",
              "      <td>0.533800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>374</td>\n",
              "      <td>0.495000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>391</td>\n",
              "      <td>0.474200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>408</td>\n",
              "      <td>0.456600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>0.424400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>442</td>\n",
              "      <td>0.388000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>459</td>\n",
              "      <td>0.377500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>476</td>\n",
              "      <td>0.360300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>493</td>\n",
              "      <td>0.344900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.334200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>527</td>\n",
              "      <td>0.327200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>544</td>\n",
              "      <td>0.310300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>561</td>\n",
              "      <td>0.316900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>578</td>\n",
              "      <td>0.293100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>595</td>\n",
              "      <td>0.284500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>612</td>\n",
              "      <td>0.276900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>629</td>\n",
              "      <td>0.266300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>646</td>\n",
              "      <td>0.270700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>663</td>\n",
              "      <td>0.253000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.258800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>697</td>\n",
              "      <td>0.256600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>714</td>\n",
              "      <td>0.256600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>731</td>\n",
              "      <td>0.238300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>748</td>\n",
              "      <td>0.244800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>765</td>\n",
              "      <td>0.235400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>782</td>\n",
              "      <td>0.232200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>799</td>\n",
              "      <td>0.234500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>816</td>\n",
              "      <td>0.222100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>833</td>\n",
              "      <td>0.227000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.222000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>867</td>\n",
              "      <td>0.219600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>884</td>\n",
              "      <td>0.218100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>901</td>\n",
              "      <td>0.214200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>918</td>\n",
              "      <td>0.216100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>935</td>\n",
              "      <td>0.204600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>952</td>\n",
              "      <td>0.212200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>969</td>\n",
              "      <td>0.203700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>986</td>\n",
              "      <td>0.201000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1003</td>\n",
              "      <td>0.196700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.196000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1037</td>\n",
              "      <td>0.190500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1054</td>\n",
              "      <td>0.190600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1071</td>\n",
              "      <td>0.196200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1088</td>\n",
              "      <td>0.188800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1105</td>\n",
              "      <td>0.185500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1122</td>\n",
              "      <td>0.185700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1139</td>\n",
              "      <td>0.186800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1156</td>\n",
              "      <td>0.186300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1173</td>\n",
              "      <td>0.177700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>0.174400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1207</td>\n",
              "      <td>0.183300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1224</td>\n",
              "      <td>0.179000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1241</td>\n",
              "      <td>0.176800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1258</td>\n",
              "      <td>0.176900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1275</td>\n",
              "      <td>0.170700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1292</td>\n",
              "      <td>0.176700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1309</td>\n",
              "      <td>0.171100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1326</td>\n",
              "      <td>0.168400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1343</td>\n",
              "      <td>0.173100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>0.161500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1377</td>\n",
              "      <td>0.163000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1394</td>\n",
              "      <td>0.165500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1411</td>\n",
              "      <td>0.156600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1428</td>\n",
              "      <td>0.162800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1445</td>\n",
              "      <td>0.163800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1462</td>\n",
              "      <td>0.155000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1479</td>\n",
              "      <td>0.158700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1496</td>\n",
              "      <td>0.159200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1513</td>\n",
              "      <td>0.156100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1530</td>\n",
              "      <td>0.163100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1547</td>\n",
              "      <td>0.145400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1564</td>\n",
              "      <td>0.155400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1581</td>\n",
              "      <td>0.149300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1598</td>\n",
              "      <td>0.151800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1615</td>\n",
              "      <td>0.152400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1632</td>\n",
              "      <td>0.141600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1649</td>\n",
              "      <td>0.141600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1666</td>\n",
              "      <td>0.147400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1683</td>\n",
              "      <td>0.151500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.137600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1717</td>\n",
              "      <td>0.147600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1734</td>\n",
              "      <td>0.143300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1751</td>\n",
              "      <td>0.142600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1768</td>\n",
              "      <td>0.142700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1785</td>\n",
              "      <td>0.143600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1802</td>\n",
              "      <td>0.138700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1819</td>\n",
              "      <td>0.136500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1836</td>\n",
              "      <td>0.143000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1853</td>\n",
              "      <td>0.141600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1870</td>\n",
              "      <td>0.137000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1887</td>\n",
              "      <td>0.135200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1904</td>\n",
              "      <td>0.132700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1921</td>\n",
              "      <td>0.135200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1938</td>\n",
              "      <td>0.138600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1955</td>\n",
              "      <td>0.131600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1972</td>\n",
              "      <td>0.136200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1989</td>\n",
              "      <td>0.134200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2006</td>\n",
              "      <td>0.137600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2023</td>\n",
              "      <td>0.133900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2040</td>\n",
              "      <td>0.127600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2057</td>\n",
              "      <td>0.138100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2074</td>\n",
              "      <td>0.132400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2091</td>\n",
              "      <td>0.126200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2108</td>\n",
              "      <td>0.130400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2125</td>\n",
              "      <td>0.124600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2142</td>\n",
              "      <td>0.121600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2159</td>\n",
              "      <td>0.131200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2176</td>\n",
              "      <td>0.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2193</td>\n",
              "      <td>0.127200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2210</td>\n",
              "      <td>0.124500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2227</td>\n",
              "      <td>0.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2244</td>\n",
              "      <td>0.127800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2261</td>\n",
              "      <td>0.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2278</td>\n",
              "      <td>0.125200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2295</td>\n",
              "      <td>0.121400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2312</td>\n",
              "      <td>0.124100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2329</td>\n",
              "      <td>0.129700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2346</td>\n",
              "      <td>0.121900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2363</td>\n",
              "      <td>0.123100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2380</td>\n",
              "      <td>0.120800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2397</td>\n",
              "      <td>0.118800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2414</td>\n",
              "      <td>0.121100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2431</td>\n",
              "      <td>0.128300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2448</td>\n",
              "      <td>0.128800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2465</td>\n",
              "      <td>0.121900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2482</td>\n",
              "      <td>0.122000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2499</td>\n",
              "      <td>0.125100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2516</td>\n",
              "      <td>0.118700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2533</td>\n",
              "      <td>0.122300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.120400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2567</td>\n",
              "      <td>0.120800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2584</td>\n",
              "      <td>0.115400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2601</td>\n",
              "      <td>0.112800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2618</td>\n",
              "      <td>0.120400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2635</td>\n",
              "      <td>0.119300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2652</td>\n",
              "      <td>0.111800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2669</td>\n",
              "      <td>0.119500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2686</td>\n",
              "      <td>0.113500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2703</td>\n",
              "      <td>0.117400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2720</td>\n",
              "      <td>0.115900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2737</td>\n",
              "      <td>0.115000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2754</td>\n",
              "      <td>0.116500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2771</td>\n",
              "      <td>0.116700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2788</td>\n",
              "      <td>0.112700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2805</td>\n",
              "      <td>0.117100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2822</td>\n",
              "      <td>0.109600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2839</td>\n",
              "      <td>0.123400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2856</td>\n",
              "      <td>0.119100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2873</td>\n",
              "      <td>0.116900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2890</td>\n",
              "      <td>0.116800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2907</td>\n",
              "      <td>0.108100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2924</td>\n",
              "      <td>0.115100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2941</td>\n",
              "      <td>0.112600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2958</td>\n",
              "      <td>0.113300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2975</td>\n",
              "      <td>0.116100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2992</td>\n",
              "      <td>0.117400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3009</td>\n",
              "      <td>0.110900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3026</td>\n",
              "      <td>0.113800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3043</td>\n",
              "      <td>0.123600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3060</td>\n",
              "      <td>0.112000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3077</td>\n",
              "      <td>0.126300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3094</td>\n",
              "      <td>0.120900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3111</td>\n",
              "      <td>0.112000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3128</td>\n",
              "      <td>0.116200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3145</td>\n",
              "      <td>0.116900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3162</td>\n",
              "      <td>0.115300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3179</td>\n",
              "      <td>0.108200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3196</td>\n",
              "      <td>0.115300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3213</td>\n",
              "      <td>0.107900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3230</td>\n",
              "      <td>0.118300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3247</td>\n",
              "      <td>0.114200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3264</td>\n",
              "      <td>0.113700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3281</td>\n",
              "      <td>0.111100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3298</td>\n",
              "      <td>0.117000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3315</td>\n",
              "      <td>0.112400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3332</td>\n",
              "      <td>0.123400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3349</td>\n",
              "      <td>0.116600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3366</td>\n",
              "      <td>0.113000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3383</td>\n",
              "      <td>0.121100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.114500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expert B (Income Statement) adapter saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3: Implement the Router and Perform Inference\n",
        "\n",
        "In our implementation, we have created a system-level Mixture-of-Experts (MoE). Instead of a single monolithic model, we use two smaller, specialized \"expert\" models, each fine-tuned on a distinct subset of financial dataone for the Balance Sheet and one for the Income Statement.\n",
        "Our route_to_financial_expert function serves as the gating network or router. This critical component analyzes the user's question and intelligently directs it to the appropriate expert, ensuring that the query is handled by the model with the most relevant training for that specific domain.\n"
      ],
      "metadata": {
        "id": "JA_x_VToPDQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "# --- 1. The Financial Router ---\n",
        "# (This remains the same)\n",
        "def route_to_financial_expert(question):\n",
        "    q_lower = question.lower()\n",
        "    if 'assets' in q_lower or 'liabilities' in q_lower:\n",
        "        return 'balance_sheet'\n",
        "    return 'income_statement'\n",
        "\n",
        "# --- 2. The Full Inference Pipeline (Simplified) ---\n",
        "# (Loading models remains the same)\n",
        "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "expert_balance_sheet = PeftModel.from_pretrained(base_model, \"./lora_expert_balance_sheet\")\n",
        "expert_income_statement = PeftModel.from_pretrained(base_model, \"./lora_expert_income_statement\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "expert_balance_sheet.to(device)\n",
        "expert_income_statement.to(device)\n",
        "\n",
        "\n",
        "# === INFERENCE FUNCTION ===\n",
        "def query_finance_system_finetune(question):\n",
        "    expert_type = route_to_financial_expert(question)\n",
        "    print(f\"Routing to... Expert '{expert_type.upper()}'\")\n",
        "\n",
        "    model_to_use = expert_balance_sheet if expert_type == 'balance_sheet' else expert_income_statement\n",
        "\n",
        "    # The model now understands the direct question-to-answer task.\n",
        "    inputs = tokenizer(question, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model_to_use.generate(**inputs, max_new_tokens=50)\n",
        "\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return answer\n",
        "\n",
        "# --- 3. Test the System ---\n",
        "print(\"\\n--- Testing the Correctly Trained Expert System ---\")\n",
        "\n",
        "question1 = \"Total liabilities of 2023?\"\n",
        "answer1 = query_finance_system_finetune(question1)\n",
        "print(f\"Q: {question1}\\nA: {answer1}\\n\")\n",
        "\n",
        "question2 = \"Revenues of 2024?\"\n",
        "answer2 = query_finance_system_finetune(question2)\n",
        "print(f\"Q: {question2}\\nA: {answer2}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O2do9ZpPFJr",
        "outputId": "1c38258d-1c1b-4023-e6f5-4bedff3b1445"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing the Correctly Trained Expert System ---\n",
            "Routing to... Expert 'BALANCE_SHEET'\n",
            "Q: Total liabilities of 2023?\n",
            "A: $ 17,026 million.\n",
            "\n",
            "Routing to... Expert 'INCOME_STATEMENT'\n",
            "Q: Revenues of 2024?\n",
            "A: $ 17,026 million.\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8021a278f3f44c978c4abe1aa696ac48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f50d726bd70e4d06aa4ed7392b917bfd",
              "IPY_MODEL_2ccfd73731364a10bc4e5133004f7aed",
              "IPY_MODEL_7bfad41bab214d9fa10a911b73092d3f"
            ],
            "layout": "IPY_MODEL_7c0c1655c5d44edca6dba07bd754ca99"
          }
        },
        "f50d726bd70e4d06aa4ed7392b917bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbd460116d154571a73b83ed842acc64",
            "placeholder": "",
            "style": "IPY_MODEL_7446cfbce4e94f69b0057cba8bff4ad1",
            "value": "Batches:100%"
          }
        },
        "2ccfd73731364a10bc4e5133004f7aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fbe551413c44965839ca1b7c13e29d1",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba9c03096fbd4937b0ffdfaf42983ef2",
            "value": 8
          }
        },
        "7bfad41bab214d9fa10a911b73092d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c472af458952457b97109019c9df0d5a",
            "placeholder": "",
            "style": "IPY_MODEL_7a49f44f4ec944c1bca765af6e9d45fa",
            "value": "8/8[00:00&lt;00:00,16.99it/s]"
          }
        },
        "7c0c1655c5d44edca6dba07bd754ca99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbd460116d154571a73b83ed842acc64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7446cfbce4e94f69b0057cba8bff4ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fbe551413c44965839ca1b7c13e29d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba9c03096fbd4937b0ffdfaf42983ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c472af458952457b97109019c9df0d5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a49f44f4ec944c1bca765af6e9d45fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c6c69330e264a6b81a22c836a19d735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_271c8c583e7040598393972740521201",
              "IPY_MODEL_0c00b1c1fac947f6b9fcf31e4dc8c420",
              "IPY_MODEL_12740e0ff0d3486f9fb336ebd1a5613f"
            ],
            "layout": "IPY_MODEL_45083e67ee9840e1b1137f3df88c5e30"
          }
        },
        "271c8c583e7040598393972740521201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_223d52fdf686452f98e32bc15972e95a",
            "placeholder": "",
            "style": "IPY_MODEL_b21a431f14ea433c8c9c0f24fb33eaf8",
            "value": "Map:100%"
          }
        },
        "0c00b1c1fac947f6b9fcf31e4dc8c420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0de7cc86102b47cdb8526eae49e70cd5",
            "max": 118,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e9296f7f7134054b91fa7cf50bfad43",
            "value": 118
          }
        },
        "12740e0ff0d3486f9fb336ebd1a5613f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c974d5780bf429cbf5fcc1894ee2e81",
            "placeholder": "",
            "style": "IPY_MODEL_038b5ff2c2f94be3b5949b0f011fdc9e",
            "value": "118/118[00:00&lt;00:00,2201.52examples/s]"
          }
        },
        "45083e67ee9840e1b1137f3df88c5e30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "223d52fdf686452f98e32bc15972e95a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b21a431f14ea433c8c9c0f24fb33eaf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0de7cc86102b47cdb8526eae49e70cd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e9296f7f7134054b91fa7cf50bfad43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c974d5780bf429cbf5fcc1894ee2e81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "038b5ff2c2f94be3b5949b0f011fdc9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c977fa9155344791b4ddd7759b94b821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4456c458485c49b6853f18860289bbde",
              "IPY_MODEL_1076b7413e0b4879a748bbab4b04e2ca",
              "IPY_MODEL_53bd4eabfdb54b18b8c94e4c74acec95"
            ],
            "layout": "IPY_MODEL_65e5e4ab924e4f05a3a4e07eb1da79c3"
          }
        },
        "4456c458485c49b6853f18860289bbde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f578fafb28c84f7ab5b1f99142029441",
            "placeholder": "",
            "style": "IPY_MODEL_b202f4894a524b6b820c255c8d8c3f7c",
            "value": "Map:100%"
          }
        },
        "1076b7413e0b4879a748bbab4b04e2ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_770d2f90e51548e8b3228b4b5ccd5a3b",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8abf45f28f8e4d36a33d22e01a89f32d",
            "value": 52
          }
        },
        "53bd4eabfdb54b18b8c94e4c74acec95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bf51213aa8a412384bbfce72ab4b08f",
            "placeholder": "",
            "style": "IPY_MODEL_40ddd0eb8c314f25b26819dfc44cb578",
            "value": "52/52[00:00&lt;00:00,805.31examples/s]"
          }
        },
        "65e5e4ab924e4f05a3a4e07eb1da79c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f578fafb28c84f7ab5b1f99142029441": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b202f4894a524b6b820c255c8d8c3f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "770d2f90e51548e8b3228b4b5ccd5a3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8abf45f28f8e4d36a33d22e01a89f32d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bf51213aa8a412384bbfce72ab4b08f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40ddd0eb8c314f25b26819dfc44cb578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "378aee5ffe29425fb8b7c1a770f07381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21ceb84030284f40b6cf1d3a23dd2e3c",
              "IPY_MODEL_b8640bd2234e44548eacba900daf75d8",
              "IPY_MODEL_b054abc048864574ab70054f5e996d9b"
            ],
            "layout": "IPY_MODEL_2803a1365caf4130bfad2ecc23a4dec3"
          }
        },
        "21ceb84030284f40b6cf1d3a23dd2e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03d2be8f3d3848d1879922bde06d7126",
            "placeholder": "",
            "style": "IPY_MODEL_30863ab3812a4513a7b516f110af18da",
            "value": "Map:100%"
          }
        },
        "b8640bd2234e44548eacba900daf75d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_084d73fb2fe54aceafa25d89de980fba",
            "max": 66,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1376084b3dd54de080eeb790d590f07a",
            "value": 66
          }
        },
        "b054abc048864574ab70054f5e996d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3f13d2820a54ba48530545fea2cc55c",
            "placeholder": "",
            "style": "IPY_MODEL_12b70de5211544b0a320cb93e10dd638",
            "value": "66/66[00:00&lt;00:00,1521.61examples/s]"
          }
        },
        "2803a1365caf4130bfad2ecc23a4dec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03d2be8f3d3848d1879922bde06d7126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30863ab3812a4513a7b516f110af18da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "084d73fb2fe54aceafa25d89de980fba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1376084b3dd54de080eeb790d590f07a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3f13d2820a54ba48530545fea2cc55c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12b70de5211544b0a320cb93e10dd638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}